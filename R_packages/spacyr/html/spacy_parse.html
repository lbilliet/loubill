<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Parse a text using spaCy</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for spacy_parse {spacyr}"><tr><td>spacy_parse {spacyr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Parse a text using spaCy</h2>

<h3>Description</h3>

<p>The <code>spacy_parse()</code> function calls spaCy to both tokenize and tag the
texts, and returns a data.table of the results. The function provides options
on the types of tagsets (<code>tagset_</code> options) either  <code>"google"</code> or
<code>"detailed"</code>, as well as lemmatization (<code>lemma</code>). It provides a
functionalities of dependency parsing and named entity recognition as an
option. If <code>"full_parse = TRUE"</code> is provided, the function returns the
most extensive list of the parsing results from spaCy.
</p>


<h3>Usage</h3>

<pre>
spacy_parse(x, pos = TRUE, tag = FALSE, lemma = TRUE, entity = TRUE,
  dependency = FALSE, multithread = TRUE, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>a character object, a <span class="pkg">quanteda</span> corpus, or a TIF-compliant
corpus data.frame (see <a href="https://github.com/ropensci/tif">https://github.com/ropensci/tif</a>)</p>
</td></tr>
<tr valign="top"><td><code>pos</code></td>
<td>
<p>logical whether to return universal dependency POS tagset
<a href="http://universaldependencies.org/u/pos/">http://universaldependencies.org/u/pos/</a>)</p>
</td></tr>
<tr valign="top"><td><code>tag</code></td>
<td>
<p>logical whether to return detailed part-of-speech tags, for the
langage model <code>en</code>, it uses the OntoNotes 5 version of the Penn
Treebank tag set (<a href="https://spacy.io/docs/usage/pos-tagging#pos-schemes">https://spacy.io/docs/usage/pos-tagging#pos-schemes</a>). 
Annotation specifications for other available languages are available on the 
spaCy website (<a href="https://spacy.io/api/annotation">https://spacy.io/api/annotation</a>).</p>
</td></tr>
<tr valign="top"><td><code>lemma</code></td>
<td>
<p>logical; inlucde lemmatized tokens in the output (lemmatization 
may not work properly for non-English models)</p>
</td></tr>
<tr valign="top"><td><code>entity</code></td>
<td>
<p>logical; if <code>TRUE</code>, report named entities</p>
</td></tr>
<tr valign="top"><td><code>dependency</code></td>
<td>
<p>logical; if <code>TRUE</code>, analyze and return dependencies</p>
</td></tr>
<tr valign="top"><td><code>multithread</code></td>
<td>
<p>logical; If true, the processing is parallelized using pipe 
functionality of spacy (<a href="https://spacy.io/api/pipe">https://spacy.io/api/pipe</a>).</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>not used directly</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> of tokenized, parsed, and annotated tokens
</p>


<h3>Examples</h3>

<pre>

spacy_initialize()
# See Chap 5.1 of the NLTK book, http://www.nltk.org/book/ch05.html
txt &lt;- "And now for something completely different."
spacy_parse(txt)
spacy_parse(txt, pos = TRUE, tag = TRUE)
spacy_parse(txt, dependency = TRUE)

txt2 &lt;- c(doc1 = "The fast cat catches mice.\\nThe quick brown dog jumped.", 
          doc2 = "This is the second document.",
          doc3 = "This is a \\\"quoted\\\" text." )
spacy_parse(txt2, entity = TRUE, dependency = TRUE)

</pre>

<hr /><div style="text-align: center;">[Package <em>spacyr</em> version 0.9.91 <a href="00Index.html">Index</a>]</div>
</body></html>
